---
title: "Bayesian Alignment Analysis (Fast Checks)"
output:
  html_document:
    toc: true
    toc_depth: 3
    theme: readable
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, message = FALSE, warning = FALSE)
```

## 0) Packages

```{r}
pacman::p_load(
  brms,
  cmdstanr,
  tidyverse,
  readr,
  tidybayes,
  ggdist,
  ggridges,
  pheatmap
)
```

## 1) Run configuration

```{r}
# Set a deterministic seed for all sampling and subsampling steps
set.seed(123)

# Metrics to run in this fast pass
metrics_list <- c(
  "lexical_jaccard",
  "pos_jaccard",
  "lsm_score",
  "semantic_similarity",
  "sentiment_similarity"
)

# Toggle smaller runs for sanity checks
fast_mode <- TRUE

# Subsampling controls (only used when fast_mode is TRUE)
max_conversations <- 2000
max_topics <- 30
min_turn_support <- 200

# Model size controls
chains_run <- if (fast_mode) 2 else 4
iter_run <- if (fast_mode) 1200 else 4000
warmup_run <- if (fast_mode) 600 else 1000
adapt_delta_run <- if (fast_mode) 0.9 else 0.95
max_treedepth_run <- if (fast_mode) 10 else 12

# Smooth term settings
use_smooth <- TRUE
smooth_k <- if (fast_mode) 6 else 12

# Backend selection
if (requireNamespace("cmdstanr", quietly = TRUE) &&
    !is.na(cmdstanr::cmdstan_version(error_on_NA = FALSE))) {
  backend_to_use <- "cmdstanr"
} else {
  backend_to_use <- "rstan"
}

cores_to_use <- min(4, parallel::detectCores())
```

## 2) Load and filter data

```{r}
df <- read_csv("../../data/outputs/merged.csv", show_col_types = FALSE)

# Keep only rows with required fields
df_clean <- df %>%
  drop_na(all_of(metrics_list), combined_topic_id, direction, turn, conv_id, combined_keywords) %>%
  mutate(
    abs_turn = abs(turn),
    direction = as.factor(direction),
    conv_id = as.factor(conv_id)
  )

# Filter A: conversation length outliers
conv_stats <- df_clean %>%
  group_by(conv_id) %>%
  summarise(n_turns = n(), .groups = "drop")

len_95 <- quantile(conv_stats$n_turns, 0.95, na.rm = TRUE)
valid_conv_ids <- conv_stats %>%
  filter(n_turns >= 2, n_turns <= len_95) %>%
  pull(conv_id)

df_filtered <- df_clean %>%
  filter(conv_id %in% valid_conv_ids)

# Filter B: turn support by absolute turn index
turn_stats <- df_filtered %>%
  group_by(abs_turn) %>%
  summarise(n_convs = n_distinct(conv_id), .groups = "drop")

valid_turns <- turn_stats %>%
  filter(n_convs >= min_turn_support) %>%
  pull(abs_turn)

df_filtered <- df_filtered %>%
  filter(abs_turn %in% valid_turns)

# Optional subsampling for fast runs
if (fast_mode) {
  sampled_convs <- sample(unique(df_filtered$conv_id), size = min(max_conversations, n_distinct(df_filtered$conv_id)))
  df_filtered <- df_filtered %>% filter(conv_id %in% sampled_convs)
}

cat("Final N rows:", nrow(df_filtered), "\n")
cat("N conversations:", n_distinct(df_filtered$conv_id), "\n")
cat("Turn range:", min(df_filtered$abs_turn), "to", max(df_filtered$abs_turn), "\n")
```

## 3) Topic labels and optional topic downsampling

```{r}
topic_info <- df_filtered %>%
  group_by(combined_topic_id) %>%
  summarise(
    raw_keywords = first(combined_keywords),
    n_convs = n_distinct(conv_id),
    .groups = "drop"
  ) %>%
  mutate(
    clean_keywords = map_chr(str_split(raw_keywords, " / "),
                             ~ paste(.x[1:min(2, length(.x))], collapse = ", ")),
    topic_label = paste0(clean_keywords, " (n=", n_convs, ")"),
    topic_label = as.factor(topic_label)
  )

df_final <- df_filtered %>%
  left_join(topic_info %>% dplyr::select(combined_topic_id, topic_label),
            by = "combined_topic_id")

# Optional topic downsampling for fast runs
if (fast_mode) {
  top_topics <- df_final %>%
    group_by(topic_label) %>%
    summarise(n_convs = n_distinct(conv_id), .groups = "drop") %>%
    arrange(desc(n_convs)) %>%
    slice_head(n = max_topics) %>%
    pull(topic_label)

  df_final <- df_final %>% filter(topic_label %in% top_topics)
}
```

## 4) Z-scoring

```{r}
df_long <- df_final %>%
  pivot_longer(all_of(metrics_list), names_to = "metric", values_to = "value")

df_long <- df_long %>%
  group_by(metric) %>%
  mutate(z = as.numeric(scale(value))) %>%
  ungroup()
```

## 5) Model specification

```{r}
my_priors <- c(
  set_prior("normal(0, 1)", class = "b"),
  set_prior("exponential(1)", class = "sd"),
  set_prior("exponential(1)", class = "sigma")
)

sampling_ctrl <- list(adapt_delta = adapt_delta_run, max_treedepth = max_treedepth_run)
```

## 6) Fit models (fast pass)

Outputs:
- bayes_fast_draws_topic_direction.csv
- bayes_fast_hierarchical_stats.csv
- bayes_fast_turn_smooth_draws.csv

```{r}
draws_topic_dir <- list()
hierarchy_stats <- list()
smooth_draws <- list()

for (m in unique(df_long$metric)) {

  cat("\n===================================================\n")
  cat("STARTING:", m, "Time:", format(Sys.time(), "%H:%M:%S"), "\n")

  d <- df_long %>% filter(metric == m)

  if (use_smooth) {
    f <- bf(z ~ 0 + topic_label * direction + s(abs_turn, k = smooth_k) + (1 | conv_id))
  } else {
    f <- bf(z ~ 0 + topic_label * direction + abs_turn + (1 | conv_id))
  }

  fit <- brm(
    formula = f,
    data = d,
    family = gaussian(),
    prior = my_priors,
    chains = chains_run,
    iter = iter_run,
    warmup = warmup_run,
    seed = 123,
    backend = backend_to_use,
    cores = cores_to_use,
    refresh = 200,
    control = sampling_ctrl
  )

  # Hierarchical stats
  vc <- VarCorr(fit)
  conv_sd <- vc$conv_id$sd[1]
  residual_sd <- if (!is.null(vc$residual$sd[1])) vc$residual$sd[1] else NA
  icc <- (conv_sd^2) / ((conv_sd^2) + (residual_sd^2))

  hierarchy_stats[[m]] <- tibble(
    metric = m,
    conv_sd = as.numeric(conv_sd),
    residual_sd = as.numeric(residual_sd),
    icc_like = as.numeric(icc)
  )

  # Topic and direction draws
  dr <- as_draws_df(fit)
  b_cols <- names(dr)[str_detect(names(dr), "^b_")]

  b_long <- dr %>%
    select(all_of(b_cols), .chain, .iteration, .draw) %>%
    pivot_longer(cols = all_of(b_cols),
                 names_to = "param",
                 values_to = "value") %>%
    mutate(metric = m)

  b_topic_dir <- b_long %>%
    filter(str_detect(param, "^b_topic_label")) %>%
    mutate(
      topic_clean = str_remove(param, "^b_topic_label"),
      topic_clean = str_replace_all(topic_clean, ":direction", " x direction")
    )

  draws_topic_dir[[m]] <- b_topic_dir

  # Smooth term draws for turn trend plotting
  turn_grid <- tibble(
    abs_turn = sort(unique(d$abs_turn)),
    topic_label = levels(d$topic_label)[1],
    direction = levels(d$direction)[1],
    conv_id = NA
  )

  smooth_epred <- posterior_epred(fit, newdata = turn_grid, re_formula = NA)
  smooth_df <- as_tibble(t(smooth_epred)) %>%
    mutate(abs_turn = turn_grid$abs_turn) %>%
    pivot_longer(cols = -abs_turn, names_to = "draw_id", values_to = "epred") %>%
    mutate(metric = m)

  smooth_draws[[m]] <- smooth_df

  write_csv(bind_rows(draws_topic_dir), "bayes_fast_draws_topic_direction.csv")
  write_csv(bind_rows(hierarchy_stats), "bayes_fast_hierarchical_stats.csv")
  write_csv(bind_rows(smooth_draws), "bayes_fast_turn_smooth_draws.csv")

  rm(fit, dr, b_long, b_topic_dir, vc, smooth_epred, smooth_df)
  gc()

  cat("DONE:", m, "\n")
}

cat("\nALL FINISHED. Outputs saved in working directory.\n")
```
